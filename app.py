import streamlit as st
from docx import Document
import pandas as pd
import matplotlib.pyplot as plt
import re
import jieba
from collections import Counter
from datetime import datetime

st.title("åœ‹å°è¾¦ã€Œæ”¿å‹™è¦èã€æ–°èç¨¿åˆ†æ")

uploaded_file = st.file_uploader("ä¸Šå‚³ Word æª”æ¡ˆï¼ˆ.docxï¼‰", type="docx")

if uploaded_file:
    doc = Document(uploaded_file)
    paragraphs = [para.text.strip() for para in doc.paragraphs if para.text.strip()]

    # æŠ½å–æ—¥æœŸèˆ‡æ¨™é¡Œ
    date_title_pairs = []
    pattern = re.compile(r'\[\s*(\d{4})[-å¹´](\d{1,2})[-æœˆ](\d{1,2})\s*\]')

    for para in paragraphs:
        match = pattern.search(para)
        if match:
            year, month, day = match.groups()
            date = datetime(int(year), int(month), int(day)).date()
            title_match = re.search(r'(?<=\]ï¼‰?(?P<title>.+)$', para)
            title = title_match.group("title") if title_match else "æœªçŸ¥æ¨™é¡Œ"
            date_title_pairs.append((date, title))

    if date_title_pairs:
        df = pd.DataFrame(date_title_pairs, columns=["date", "title"])
        df['month'] = df['date'].apply(lambda d: d.strftime('%Y-%m'))
        df['count'] = 1

        st.subheader("ğŸ“ˆ ç™¼å¸ƒé‡æ™‚é–“æŠ˜ç·šåœ–")
        df_daily = df.groupby("date").count().rename(columns={"count": "news_count"})
        st.line_chart(df_daily["news_count"])

        st.subheader("ğŸ“° æ–°èç™¼å¸ƒç´€éŒ„ï¼ˆå‰20ç­†ï¼‰")
        st.dataframe(df[['date', 'title']].head(20))

        # å‰20å¤§ä¸­æ–‡é—œéµå­—
        all_text = " ".join(df['title'].tolist())
        words = jieba.lcut(all_text)
        words = [w for w in words if len(w) > 1 and not re.match(r'[\d\W]+', w)]
        counter = Counter(words)
        most_common = counter.most_common(20)

        st.subheader("ğŸ”‘ æ–°èç¨¿å‰20å¤§ä¸­æ–‡é—œéµå­—")
        for word, freq in most_common:
            st.write(f"{word}: {freq}")

        # ç™¼ç¨¿æœ€å¤šçš„æœˆä»½
        st.subheader("ğŸ“… æ–°èç¨¿æœ€å¤šçš„æœˆä»½")
        month_count = df.groupby("month")["count"].sum()
        top_month = month_count.idxmax()
        st.write(f"æœ€å¤šç™¼ç¨¿æœˆä»½ï¼š{top_month}ï¼ˆ{month_count.max()} ç¯‡ï¼‰")

        # è©²æœˆä»½é—œéµå­—åˆ†æ
        top_month_titles = df[df['month'] == top_month]['title'].tolist()
        month_text = " ".join(top_month_titles)
        month_words = jieba.lcut(month_text)
        month_words = [w for w in month_words if len(w) > 1 and not re.match(r'[\d\W]+', w)]
        month_counter = Counter(month_words)
        month_common = month_counter.most_common(20)

        st.subheader("ğŸ—“ï¸ æœ€å¤šæœˆä»½çš„å‰20å¤§é—œéµå­—")
        for word, freq in month_common:
            st.write(f"{word}: {freq}")

        # èˆ‡ã€Œå…©å²¸ã€æœ‰é—œçš„é—œéµå­—ï¼ˆç°¡é«”ï¼‰
        st.subheader("ğŸ” èˆ‡ã€Œä¸¤å²¸ã€ç›¸é—œçš„é—œéµå­—")
        liangan_related = [w for w in counter if 'ä¸¤å²¸' in w]
        for word in liangan_related:
            st.write(f"{word}: {counter[word]}")

        # èˆ‡ã€Œå°ç¨ã€æœ‰é—œçš„é—œéµå­—ï¼ˆç°¡é«”ï¼‰
        st.subheader("ğŸ§¨ èˆ‡ã€Œå°ç‹¬ã€ç›¸é—œçš„é—œéµå­—")
        taidu_related = [w for w in counter if 'å°ç‹¬' in w]
        for word in taidu_related:
            st.write(f"{word}: {counter[word]}")
